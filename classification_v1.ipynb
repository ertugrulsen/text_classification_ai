{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "9bNoTrrLq9rG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a644f5ff-c01c-48af-a375-72cfa89c63cb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.3.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.16.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install zemberek-python"
      ],
      "metadata": {
        "id": "04q15EN1cwfr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29e27d12-c27c-427c-8d02-6c0172fad6e0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: zemberek-python in /usr/local/lib/python3.10/dist-packages (0.2.3)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.10/dist-packages (from zemberek-python) (4.8)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from zemberek-python) (1.23.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ZEMBEREK TEST**"
      ],
      "metadata": {
        "id": "MsSlLOnFjE9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import logging\n",
        "\n",
        "from zemberek import (\n",
        "    TurkishSpellChecker,\n",
        "    TurkishSentenceNormalizer,\n",
        "    TurkishSentenceExtractor,\n",
        "    TurkishMorphology,\n",
        "    TurkishTokenizer\n",
        ")\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "examples = [\"Yrn okua gidicem\",\n",
        "            \"Tmm, yarin havuza giricem ve aksama kadar yaticam :)\",\n",
        "            \"ah aynen ya annemde fark ettı siz evinizden cıkmayın diyo\",\n",
        "            \"gercek mı bu? Yuh! Artık unutulması bile beklenmiyo\",\n",
        "            \"Hayır hayat telaşm olmasa alacam buraları gökdelen dikicem.\",\n",
        "            \"yok hocam kesınlıkle oyle birşey yok\",\n",
        "            \"herseyi soyle hayatında olmaması gerek bence boyle ınsanların falan baskı yapıyosa\",\n",
        "            \"email adresim zemberek_python@loodos.com\",\n",
        "            \"Kredi başvrusu yapmk istiyrum.\",\n",
        "            \"Bankanizin hesp blgilerini ogrenmek istyorum.\"]\n",
        "\n",
        "morphology = TurkishMorphology.create_with_defaults()\n",
        "\n",
        "# SENTENCE NORMALIZATION\n",
        "start = time.time()\n",
        "normalizer = TurkishSentenceNormalizer(morphology)\n",
        "logger.info(f\"Normalization instance created in: {time.time() - start} s\")\n",
        "\n",
        "start = time.time()\n",
        "for example in examples:\n",
        "    print(example)\n",
        "    print(normalizer.normalize(example), \"\\n\")\n",
        "logger.info(f\"Sentences normalized in: {time.time() - start} s\")\n",
        "\n",
        "start = time.time()\n",
        "sc = TurkishSpellChecker(morphology)\n",
        "logger.info(f\"Spell checker instance created in: {time.time() - start} s\")\n",
        "\n",
        "\n",
        "# SPELLING SUGGESTION\n",
        "li = [\"okuyablirim\", \"tartısıyor\", \"Ankar'ada\", \"knlıca\", \"yapablrim\", \"kıredi\", \"geldm\", \"geliyom\", \"aldm\", \"asln\"]\n",
        "start = time.time()\n",
        "for word in li:\n",
        "    print(word + \" = \" + ' '.join(sc.suggest_for_word(word)))\n",
        "logger.info(f\"Spells checked in: {time.time() - start} s\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWepAfbSd3b8",
        "outputId": "4b0ecbe3-d3f9-47cc-c5c8-71c56d7fec51"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:zemberek.morphology.turkish_morphology:TurkishMorphology instance initialized in 15.359509229660034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-08-12 10:00:52,097 - zemberek.morphology.turkish_morphology - INFO\n",
            "Msg: TurkishMorphology instance initialized in 15.359509229660034\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:Normalization instance created in: 24.822957277297974 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-08-12 10:01:16,931 - __main__ - INFO\n",
            "Msg: Normalization instance created in: 24.822957277297974 s\n",
            "\n",
            "Yrn okua gidicem\n",
            "yarın okula gideceğim \n",
            "\n",
            "Tmm, yarin havuza giricem ve aksama kadar yaticam :)\n",
            "tamam , yarın havuza gireceğim ve akşama kadar yatacağım :) \n",
            "\n",
            "ah aynen ya annemde fark ettı siz evinizden cıkmayın diyo\n",
            "ah aynen ya annemde fark etti siz evinizden çıkmayın diyor \n",
            "\n",
            "gercek mı bu? Yuh! Artık unutulması bile beklenmiyo\n",
            "gerçek mi bu ? yuh ! artık unutulması bile beklenmiyor \n",
            "\n",
            "Hayır hayat telaşm olmasa alacam buraları gökdelen dikicem.\n",
            "hayır hayat telaşı olmasa alacağım buraları gökdelen dikeceğim . \n",
            "\n",
            "yok hocam kesınlıkle oyle birşey yok\n",
            "yok hocam kesinlikle öyle bir şey yok \n",
            "\n",
            "herseyi soyle hayatında olmaması gerek bence boyle ınsanların falan baskı yapıyosa\n",
            "herşeyi söyle hayatında olmaması gerek bence böyle insanların falan baskı yapıyorsa \n",
            "\n",
            "email adresim zemberek_python@loodos.com\n",
            "mail adresim zemberek_python@loodos.com \n",
            "\n",
            "Kredi başvrusu yapmk istiyrum.\n",
            "kredi başvurusu yapmak istiyorum . \n",
            "\n",
            "Bankanizin hesp blgilerini ogrenmek istyorum.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:Sentences normalized in: 3.0638530254364014 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bankanızın hesap bilgilerini öğrenmek istiyorum . \n",
            "\n",
            "2023-08-12 10:01:20,005 - __main__ - INFO\n",
            "Msg: Sentences normalized in: 3.0638530254364014 s\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:Spell checker instance created in: 11.644546270370483 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-08-12 10:01:31,658 - __main__ - INFO\n",
            "Msg: Spell checker instance created in: 11.644546270370483 s\n",
            "\n",
            "okuyablirim = okuyabilirim\n",
            "tartısıyor = tartışıyor tartılıyor\n",
            "Ankar'ada = Ankara'da Ankara'ya Ankara'dan Ankara'nda Antara'da Ankara'ma Ankaray'da Ankaray'a Ankara'na Angara'da Anakara'da Ankara'mda Ankara'ca\n",
            "knlıca = kanlıca kanlıca kalıca kınlıca anlıca kılıca\n",
            "yapablrim = \n",
            "kıredi = kredi küredi\n",
            "geldm = geldi geldim gelem gelim\n",
            "geliyom = geliyor geliyim\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:Spells checked in: 0.3657052516937256 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aldm = aldı alım aldım alem alim alim alam aldo aldi Aldo'm Al'ım alda Al'da Al'dım Al'dı Aldi'm\n",
            "asln = asla aslan aslan aslı aslı asli aslen asan asın As'la As'ın As'lın As'lı Aslı'n As'lan assn asin aslin aslın\n",
            "2023-08-12 10:01:32,030 - __main__ - INFO\n",
            "Msg: Spells checked in: 0.3657052516937256 s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VERİ BİLGİLERİ**"
      ],
      "metadata": {
        "id": "6JGuSu3qzQK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"sikayetimVar.csv\")\n",
        "\n",
        "{0: \"müşteri hizmetleri\",\n",
        "                1: \"kredi başvurusu\",\n",
        "                2: \"mobil uygulama\",\n",
        "                3: \"ücretlendirme\",\n",
        "                4: \"atm\",\n",
        "                5: \"kredi kartı\",\n",
        "                6: \"internet bankacılığı\",\n",
        "                7: \"faiz işlem\",\n",
        "                8: \"şube hizmeti\",\n",
        "                9: \"çağrı merkezi\",\n",
        "                10: \"para transferi\",\n",
        "                11: \"pos\", }\n",
        "\n",
        "categories = [\"kredi başvurusu\", \"mobil uygulama\", \"ücretlendirme\", \"atm\", \"kredi kartı\", \"internet bankacılığı\", \"faiz işlem\", \"şube hizmeti\", \"çağrı merkezi\", \"para transferi\", \"pos\"]\n",
        "\n",
        "for category in categories:\n",
        "  selected_column = 'category'\n",
        "  selected_value = category\n",
        "\n",
        "  count = data[selected_column].value_counts()[selected_value]\n",
        "  print(f\"'{selected_value}' değeri {count} kez bulunuyor.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wU5bDQvMzPld",
        "outputId": "468773da-651b-4296-d94b-9ac4a70ab3cc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-08-12 10:01:32,122 - numexpr.utils - INFO\n",
            "Msg: NumExpr defaulting to 2 threads.\n",
            "\n",
            "'kredi başvurusu' değeri 270 kez bulunuyor.\n",
            "'mobil uygulama' değeri 270 kez bulunuyor.\n",
            "'ücretlendirme' değeri 265 kez bulunuyor.\n",
            "'atm' değeri 268 kez bulunuyor.\n",
            "'kredi kartı' değeri 270 kez bulunuyor.\n",
            "'internet bankacılığı' değeri 270 kez bulunuyor.\n",
            "'faiz işlem' değeri 270 kez bulunuyor.\n",
            "'şube hizmeti' değeri 270 kez bulunuyor.\n",
            "'çağrı merkezi' değeri 270 kez bulunuyor.\n",
            "'para transferi' değeri 270 kez bulunuyor.\n",
            "'pos' değeri 260 kez bulunuyor.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stop-words"
      ],
      "metadata": {
        "id": "OQ8KKtpyptGm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8474e4c-0678-490d-f4a1-aab6a475d83b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stop-words in /usr/local/lib/python3.10/dist-packages (2018.7.23)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "from zemberek import (\n",
        "    TurkishSpellChecker,\n",
        "    TurkishSentenceNormalizer,\n",
        "    TurkishSentenceExtractor,\n",
        "    TurkishMorphology,\n",
        "    TurkishTokenizer\n",
        ")\n",
        "from stop_words import get_stop_words\n",
        "\n",
        "data = pd.read_csv(\"sikayetimVar.csv\")\n",
        "\n",
        "morphology = TurkishMorphology.create_with_defaults()\n",
        "normalizer = TurkishSentenceNormalizer(morphology)\n",
        "\n",
        "stop_words = get_stop_words('tr')\n",
        "\n",
        "# Temel ön işleme adımları\n",
        "def preprocess_with_zemberek(text):\n",
        "  preprocessed_text = normalizer.normalize(text)\n",
        "\n",
        "  # Stop kelimeleri çıkar\n",
        "  preprocessed_text = \" \".join([token for token in preprocessed_text.split() if token not in stop_words])\n",
        "\n",
        "  return preprocessed_text\n",
        "\n",
        "preprocessed_texts = []\n",
        "first_labels = []\n",
        "\n",
        "# Tüm satırları gez\n",
        "for index, row in data.iterrows():\n",
        "  text = row[\"text\"]\n",
        "  label = row[\"category\"]\n",
        "\n",
        "  text = preprocess_with_zemberek(text)\n",
        "\n",
        "  preprocessed_texts.append(text)\n",
        "  first_labels.append(label)\n",
        "\n",
        "dfData = {\n",
        "    'text': preprocessed_texts,\n",
        "    'category': first_labels\n",
        "}\n",
        "\n",
        "data = pd.DataFrame(dfData)\n",
        "\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "2tTLxTtIcWpa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1896149f-e51d-4566-de6f-f29c09b0d5f2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /tmp/tmpoi52n3vl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-08-12 10:01:44,802 - torch.distributed.nn.jit.instantiator - INFO\n",
            "Msg: Created a temporary directory at /tmp/tmpoi52n3vl\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:torch.distributed.nn.jit.instantiator:Writing /tmp/tmpoi52n3vl/_remote_module_non_scriptable.py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-08-12 10:01:44,830 - torch.distributed.nn.jit.instantiator - INFO\n",
            "Msg: Writing /tmp/tmpoi52n3vl/_remote_module_non_scriptable.py\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:zemberek.morphology.turkish_morphology:TurkishMorphology instance initialized in 24.11278510093689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-08-12 10:02:15,748 - zemberek.morphology.turkish_morphology - INFO\n",
            "Msg: TurkishMorphology instance initialized in 24.11278510093689\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"dbmdz/distilbert-base-turkish-cased\"\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "train_encodings = tokenizer(list(train_data[\"text\"]), truncation=True, padding=True)\n",
        "test_encodings = tokenizer(list(test_data[\"text\"]), truncation=True, padding=True)\n",
        "\n",
        "label2id = {label: i for i, label in enumerate(train_data[\"category\"].unique())}\n",
        "train_labels = [label2id[label] for label in train_data[\"category\"]]\n",
        "test_labels = [label2id[label] for label in test_data[\"category\"]]\n",
        "\n",
        "train_dataset = Dataset.from_dict({\"input_ids\": train_encodings[\"input_ids\"], \"attention_mask\": train_encodings[\"attention_mask\"], \"label\": train_labels})\n",
        "test_dataset = Dataset.from_dict({\"input_ids\": test_encodings[\"input_ids\"], \"attention_mask\": test_encodings[\"attention_mask\"], \"label\": test_labels})\n"
      ],
      "metadata": {
        "id": "ir5aZ_tXqIyP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch]"
      ],
      "metadata": {
        "id": "rRjegemorbNO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1100c167-b44f-4b32-a9af-67a49f0904db"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.3.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.0)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.0.1+cu118)\n",
            "Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.21.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[torch]) (3.27.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[torch]) (16.0.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.9->transformers[torch]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.9->transformers[torch]) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=len(label2id))\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./tranings\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    logging_steps=500,\n",
        "    save_steps=1000,\n",
        "    logging_dir=\"./logs\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")\n",
        "trainer.train()\n",
        "model.save_pretrained(\"/models\")"
      ],
      "metadata": {
        "id": "LMN-GpOPqLU5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "d9aa27f7-965e-4b12-eae5-c93b53668be9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at dbmdz/distilbert-base-turkish-cased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3870' max='3870' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3870/3870 03:06, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.915900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.087400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.082300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.039600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.042200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.029400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.005400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CLASSIFICATION REPORT**"
      ],
      "metadata": {
        "id": "WbM6ugCxU1SQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Modeli test verisi üzerinde değerlendirin ve tahminleri alın\n",
        "predictions = trainer.predict(test_dataset)\n",
        "predicted_labels = predictions.predictions.argmax(axis=1)\n",
        "true_labels = predictions.label_ids\n",
        "# classification_report'u kullanarak raporu oluşturun\n",
        "report = classification_report(true_labels, predicted_labels)\n",
        "# Raporu bastırın\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "GHq8y5wbUfKX",
        "outputId": "e32946cf-a874-42f4-aae2-514f249f0ba4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        57\n",
            "           1       1.00      0.98      0.99        51\n",
            "           2       1.00      0.98      0.99        61\n",
            "           3       1.00      1.00      1.00        54\n",
            "           4       0.98      1.00      0.99        57\n",
            "           5       1.00      1.00      1.00        54\n",
            "           6       1.00      0.98      0.99        62\n",
            "           7       1.00      1.00      1.00        53\n",
            "           8       0.96      0.98      0.97        48\n",
            "           9       0.98      0.98      0.98        54\n",
            "          10       1.00      1.00      1.00        53\n",
            "          11       0.98      1.00      0.99        41\n",
            "\n",
            "    accuracy                           0.99       645\n",
            "   macro avg       0.99      0.99      0.99       645\n",
            "weighted avg       0.99      0.99      0.99       645\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PREDICT PART**"
      ],
      "metadata": {
        "id": "DojZ61zRsSqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification,BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "def load_model():\n",
        "    #model = DistilBertForSequenceClassification.from_pretrained(\"models\", cache_dir=\"./cache\")  # Model dosyaları ./cache klasörüne indirilecek\n",
        "    model = DistilBertForSequenceClassification.from_pretrained(\"/models\")\n",
        "    tokenizer = DistilBertTokenizer.from_pretrained(\"dbmdz/distilbert-base-turkish-cased\")  # Tokenizer dosyaları ./cache klasörüne indirilecek\n",
        "    return model, tokenizer\n",
        "\n",
        "\n",
        "\n",
        "def classify_text(text, model, tokenizer):\n",
        "    encoding = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**encoding)\n",
        "    logits = outputs.logits\n",
        "    predicted_class = torch.argmax(logits).item()\n",
        "\n",
        "    return predicted_class\n",
        "\n",
        "model, tokenizer = load_model()\n",
        "\n",
        "sample_texts = [\n",
        "    \"Müşteri hizmetleri çağrı merkezine ulaşmak için karmaşık menüleri takip etmek zorunda kaldım\",\n",
        "    \"Kredi başvurusu için gereken belgeleri tamamladım ancak bankanızın belirttiği sürede geri dönüş alamadım\",\n",
        "    \"Müşteri hizmetleri temsilciniz hesap kesim tarihimi değiştirmem konusunda yardımcı oldu\",\n",
        "    \"Kredi başvurusu sırasında banka yetkilileri güler yüzlü ve yardımsever davrandı\",\n",
        "    \"Banka aracılığıyla yaptığım EFT işlemi uzun süreli gecikmelerle karşılaşıyor\",\n",
        "    \"Mobil uygulamanızın arayüzü şık ve basit kullanımı oldukça keyifli\",\n",
        "    \"Ücretlendirme politikanız müşterilere sağladığınız avantajlarla dengeli ve adil bir şekilde uygulanıyor\",\n",
        "    \"ATM'lerinizdeki işlem hızı oldukça hızlı bekleme süresi minimum düzeyde\",\n",
        "    \"POS cihazınızın işlem hızı oldukça yüksek sıra beklemeden ödeme yapabiliyorum\",\n",
        "    \"Şubenizdeki hizmet kalitesi memnuniyetimi sağlayacak düzeyde ve başarılıydı\",\n",
        "    \"Faiz işlemi sırasında hesabımdan fazla faiz kesildi iade talep ediyorum\"\n",
        "]\n",
        "\n",
        "for text in sample_texts:\n",
        "    preprocessed_text = preprocess_with_zemberek(text)\n",
        "    predicted_class = classify_text(preprocessed_text, model, tokenizer)\n",
        "    label2id = {0: \"müşteri hizmetleri\",\n",
        "                1: \"kredi başvurusu\",\n",
        "                2: \"mobil uygulama\",\n",
        "                3: \"ücretlendirme\",\n",
        "                4: \"atm\",\n",
        "                5: \"kredi kartı\",\n",
        "                6: \"internet bankacılığı\",\n",
        "                7: \"faiz işlem\",\n",
        "                8: \"şube hizmeti\",\n",
        "                9: \"çağrı merkezi\",\n",
        "                10: \"para transferi\",\n",
        "                11: \"pos\", }\n",
        "\n",
        "    predicted_category = label2id[predicted_class]\n",
        "    print(f\"Metin: {text}\")\n",
        "    print(f\"Tahmin: {predicted_category}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0sOYWxVsW6k",
        "outputId": "c11bbd64-9c61-4c72-8905-c3c5eaf8f723"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metin: Müşteri hizmetleri çağrı merkezine ulaşmak için karmaşık menüleri takip etmek zorunda kaldım\n",
            "Tahmin: kredi başvurusu\n",
            "\n",
            "Metin: Kredi başvurusu için gereken belgeleri tamamladım ancak bankanızın belirttiği sürede geri dönüş alamadım\n",
            "Tahmin: pos\n",
            "\n",
            "Metin: Müşteri hizmetleri temsilciniz hesap kesim tarihimi değiştirmem konusunda yardımcı oldu\n",
            "Tahmin: kredi başvurusu\n",
            "\n",
            "Metin: Kredi başvurusu sırasında banka yetkilileri güler yüzlü ve yardımsever davrandı\n",
            "Tahmin: pos\n",
            "\n",
            "Metin: Banka aracılığıyla yaptığım EFT işlemi uzun süreli gecikmelerle karşılaşıyor\n",
            "Tahmin: çağrı merkezi\n",
            "\n",
            "Metin: Mobil uygulamanızın arayüzü şık ve basit kullanımı oldukça keyifli\n",
            "Tahmin: ücretlendirme\n",
            "\n",
            "Metin: Ücretlendirme politikanız müşterilere sağladığınız avantajlarla dengeli ve adil bir şekilde uygulanıyor\n",
            "Tahmin: şube hizmeti\n",
            "\n",
            "Metin: ATM'lerinizdeki işlem hızı oldukça hızlı bekleme süresi minimum düzeyde\n",
            "Tahmin: kredi kartı\n",
            "\n",
            "Metin: POS cihazınızın işlem hızı oldukça yüksek sıra beklemeden ödeme yapabiliyorum\n",
            "Tahmin: para transferi\n",
            "\n",
            "Metin: Şubenizdeki hizmet kalitesi memnuniyetimi sağlayacak düzeyde ve başarılıydı\n",
            "Tahmin: internet bankacılığı\n",
            "\n",
            "Metin: Faiz işlemi sırasında hesabımdan fazla faiz kesildi iade talep ediyorum\n",
            "Tahmin: faiz işlem\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x19xUDcbx2E-"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}